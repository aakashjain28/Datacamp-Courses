{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 1 - Preparing the data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the dataset\n",
    "\n",
    "Throughout this course, you'll be analyzing a dataset of traffic stops in Rhode Island that was collected by the Stanford Open Policing Project.\n",
    "\n",
    "Before beginning your analysis, it's important that you familiarize yourself with the dataset. In this exercise, you'll read the dataset into pandas, examine the first few rows, and then count the number of missing values.\n",
    "\n",
    "### Instructions\n",
    "* Import `pandas` using the alias `pd`.\n",
    "* Read the file `police.csv` into a DataFrame named `ri`.\n",
    "* Examine the first 5 rows of the DataFrame (known as the \"head\").\n",
    "* Count the number of missing values in each column: Use `.isnull()` to check which DataFrame elements are missing, and then take the `.sum()` to count the number of `True` values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'police.csv' into a DataFrame named ri\n",
    "ri = pd.read_csv('police.csv')\n",
    "\n",
    "# Examine the head of the DataFrame\n",
    "print(ri.head())\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "print(ri.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns\n",
    "\n",
    "Often, a DataFrame will contain columns that are not useful to your analysis. Such columns should be dropped from the DataFrame, to make it easier for you to focus on the remaining columns.\n",
    "\n",
    "In this exercise, you'll drop the county_name column because it only contains missing values, and you'll drop the `state` column because all of the traffic stops took place in one state (Rhode Island). Thus, these columns can be dropped because they contain no useful information. The number of missing values in each column has been printed to the console for you.\n",
    "\n",
    "### Instructions\n",
    "* Examine the DataFrame's `.shape` to find out the number of rows and columns.\n",
    "* Drop both the `county_name` and `state` columns by passing the column names to the `.drop()` method as a list of strings.\n",
    "* Examine the `.shape` again to verify that there are now two fewer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of the DataFrame\n",
    "print(ri.shape)\n",
    "\n",
    "# Drop the 'county_name' and 'state' columns\n",
    "ri.drop(['county_name', 'state'], axis='columns', inplace=True)\n",
    "\n",
    "# Examine the shape of the DataFrame (again)\n",
    "print(ri.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows\n",
    "\n",
    "When you know that a specific column will be critical to your analysis, and only a small fraction of rows are missing a value in that column, it often makes sense to remove those rows from the dataset.\n",
    "\n",
    "During this course, the `driver_gender` column will be critical to many of your analyses. Because only a small fraction of rows are missing `driver_gender`, we'll drop those rows from the dataset.\n",
    "\n",
    "### Instructions\n",
    "* Count the number of missing values in each column.\n",
    "* Drop all rows that are missing `driver_gender` by passing the column name to the `subset` parameter of `.dropna()`.\n",
    "* Count the number of missing values in each column again, to verify that none of the remaining rows are missing `driver_gender`.\n",
    "* Examine the DataFrame's `.shape` to see how many rows and columns remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values in each column\n",
    "print(ri.isnull().sum())\n",
    "\n",
    "# Drop all rows that are missing 'driver_gender'\n",
    "ri.dropna(subset=['driver_gender'], inplace=True)\n",
    "\n",
    "# Count the number of missing values in each column (again)\n",
    "print(ri.isnull().sum())\n",
    "\n",
    "# Examine the shape of the DataFrame\n",
    "print(ri.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing a data type\n",
    "\n",
    "We saw in the previous exercise that the `is_arrested` column currently has the `object` data type. In this exercise, we'll change the data type to `bool`, which is the most suitable type for a column containing `True` and `False` values.\n",
    "\n",
    "Fixing the data type will enable us to use mathematical operations on the `is_arrested` column that would not be possible otherwise.\n",
    "\n",
    "### Instructions\n",
    "* Examine the head of the `is_arrested` column to verify that it contains `True` and `False` values and to check the column's data type.\n",
    "* Use the `.astype()` method to convert `is_arrested` to a `bool` column.\n",
    "* Check the new data type of `is_arrested` to confirm that it is now a `bool` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the head of the 'is_arrested' column\n",
    "print(ri.is_arrested.head())\n",
    "\n",
    "# Change the data type of 'is_arrested' to 'bool'\n",
    "ri['is_arrested'] = ri.is_arrested.astype('bool')\n",
    "\n",
    "# Check the data type of 'is_arrested' \n",
    "print(ri.is_arrested.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining object columns\n",
    "\n",
    "Currently, the date and time of each traffic stop are stored in separate object columns: stop_date and stop_time.\n",
    "\n",
    "In this exercise, you'll combine these two columns into a single column, and then convert it to datetime format. This will enable convenient date-based attributes that we'll use later in the course.\n",
    "\n",
    "### Instructions\n",
    "* Use a string method to concatenate `stop_date` and `stop_time` (separated by a space), and store the result in `combined`.\n",
    "* Convert `combined` to `datetime` format, and store the result in a new column named `stop_datetime`.\n",
    "* Examine the DataFrame `.dtypes` to confirm that `stop_datetime` is a datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'stop_date' and 'stop_time' (separated by a space)\n",
    "combined = ri.stop_date.str.cat(ri.stop_time, sep=' ')\n",
    "\n",
    "# Convert 'combined' to datetime format\n",
    "ri['stop_datetime'] = pd.to_datetime(combined)\n",
    "\n",
    "# Examine the data types of the DataFrame\n",
    "print(ri.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the index\n",
    "\n",
    "The last step that you'll take in this chapter is to set the stop_datetime column as the DataFrame's index. By replacing the default index with a DatetimeIndex, you'll make it easier to analyze the dataset by date and time, which will come in handy later in the course!\n",
    "\n",
    "### Instructions\n",
    "* Set `stop_datetime` as the DataFrame index.\n",
    "* Examine the index to verify that it is a DatetimeIndex.\n",
    "* Examine the DataFrame columns to confirm that `stop_datetime` is no longer one of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'stop_datetime' as the index\n",
    "ri.set_index('stop_datetime', inplace=True)\n",
    "\n",
    "# Examine the index\n",
    "print(ri.index)\n",
    "\n",
    "# Examine the columns\n",
    "print(ri.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 2 - Exploring the relationship between gender and policing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining traffic violations\n",
    "\n",
    "Before comparing the violations being committed by each gender, you should examine the violations committed by all drivers to get a baseline understanding of the data.\n",
    "\n",
    "In this exercise, you'll count the unique values in the `violation` column, and then separately express those counts as proportions.\n",
    "\n",
    "### Instructions\n",
    "* Count the unique values in the `violation` column of the `ri` DataFrame, to see what violations are being committed by all drivers.\n",
    "* Express the violation counts as proportions of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the unique values in 'violation'\n",
    "print(ri['violation'].value_counts())\n",
    "\n",
    "# Express the counts as proportions\n",
    "print(ri['violation'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing violations by gender\n",
    "\n",
    "The question we're trying to answer is whether male and female drivers tend to commit different types of traffic violations.\n",
    "\n",
    "In this exercise, you'll first create a DataFrame for each gender, and then analyze the violations in each DataFrame separately.\n",
    "\n",
    "### Instructions\n",
    "* Create a DataFrame, `female`, that only contains rows in which `driver_gender` is `'F'`.\n",
    "* Create a DataFrame, `male`, that only contains rows in which `driver_gender` is `'M'`.\n",
    "* Count the violations committed by female drivers and express them as proportions.\n",
    "* Count the violations committed by male drivers and express them as proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of female drivers\n",
    "female = ri[ri['driver_gender'] == 'F']\n",
    "\n",
    "# Create a DataFrame of male drivers\n",
    "male = ri[ri['driver_gender'] == 'M']\n",
    "\n",
    "# Compute the violations by female drivers (as proportions)\n",
    "print(female['violation'].value_counts(normalize=True))\n",
    "\n",
    "# Compute the violations by male drivers (as proportions)\n",
    "print(male['violation'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing speeding outcomes by gender\n",
    "\n",
    "When a driver is pulled over for speeding, many people believe that gender has an impact on whether the driver will receive a ticket or a warning. Can you find evidence of this in the dataset?\n",
    "\n",
    "First, you'll create two DataFrames of drivers who were stopped for speeding: one containing females and the other containing males.\n",
    "\n",
    "Then, for each gender, you'll use the `stop_outcome` column to calculate what percentage of stops resulted in a `\"Citation\"` (meaning a ticket) versus a `\"Warning\"`.\n",
    "\n",
    "### Instructions\n",
    "* Create a DataFrame, `female_and_speeding`, that only includes female drivers who were stopped for speeding.\n",
    "* Create a DataFrame, `male_and_speeding`, that only includes male drivers who were stopped for speeding.\n",
    "* Count the stop outcomes for the female drivers and express them as proportions.\n",
    "* Count the stop outcomes for the male drivers and express them as proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of female drivers stopped for speeding\n",
    "female_and_speeding = ri[(ri['driver_gender'] == 'F') & (ri['violation'] == 'Speeding')]\n",
    "\n",
    "# Create a DataFrame of male drivers stopped for speeding\n",
    "male_and_speeding = ri[(ri['driver_gender'] == 'M') & (ri['violation'] == 'Speeding')]\n",
    "\n",
    "# Compute the stop outcomes for female drivers (as proportions)\n",
    "print(female_and_speeding['stop_outcome'].value_counts(normalize=True))\n",
    "\n",
    "# Compute the stop outcomes for male drivers (as proportions)\n",
    "print(male_and_speeding['stop_outcome'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the search rate\n",
    "\n",
    "During a traffic stop, the police officer sometimes conducts a search of the vehicle. In this exercise, you'll calculate the percentage of all stops in the `ri` DataFrame that result in a vehicle search, also known as the search rate.\n",
    "\n",
    "### Instructions\n",
    "* Check the data type of `search_conducted` to confirm that it's a Boolean Series.\n",
    "* Calculate the search rate by counting the Series values and expressing them as proportions.\n",
    "* Calculate the search rate by taking the mean of the Series. (It should match the proportion of `True` values calculated above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of 'search_conducted'\n",
    "print(ri['search_conducted'].dtype)\n",
    "\n",
    "# Calculate the search rate by counting the values\n",
    "print(ri.search_conducted.value_counts(normalize=True))\n",
    "\n",
    "# Calculate the search rate by taking the mean\n",
    "print(ri['search_conducted'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing search rates by gender\n",
    "\n",
    "In this exercise, you'll compare the rates at which female and male drivers are searched during a traffic stop. Remember that the vehicle search rate across all stops is about 3.8%.\n",
    "\n",
    "First, you'll filter the DataFrame by gender and calculate the search rate for each group separately. Then, you'll perform the same calculation for both genders at once using a `.groupby()`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Section 1\n",
    "* Filter the DataFrame to only include female drivers, and then calculate the search rate by taking the mean of search_conducted.\n",
    "\n",
    "#### Section 2\n",
    "* Filter the DataFrame to only include male drivers, and then repeat the search rate calculation.\n",
    "\n",
    "#### Section 3\n",
    "* Group by driver gender to calculate the search rate for both groups simultaneously. (It should match the previous results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the search rate for female drivers\n",
    "print(ri[ri['driver_gender'] == 'F'].search_conducted.mean())\n",
    "\n",
    "# Calculate the search rate for male drivers\n",
    "print(ri[ri['driver_gender'] == 'M'].search_conducted.mean())\n",
    "\n",
    "# Calculate the search rate for both groups simultaneously\n",
    "print(ri.groupby(['driver_gender']).search_conducted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a second factor to the analysis\n",
    "\n",
    "Even though the search rate for males is much higher than for females, it's possible that the difference is mostly due to a second factor.\n",
    "\n",
    "For example, you might hypothesize that the search rate varies by violation type, and the difference in search rate between males and females is because they tend to commit different violations.\n",
    "\n",
    "You can test this hypothesis by examining the search rate for each combination of gender and violation. If the hypothesis was true, you would find that males and females are searched at about the same rate for each violation. Find out below if that's the case!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Section 1\n",
    "* Use a `.groupby()` to calculate the search rate for each combination of gender and violation. Are males and females searched at about the same rate for each violation?\n",
    "\n",
    "#### Section 2\n",
    "* Reverse the ordering to group by violation before gender. The results may be easier to compare when presented this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the search rate for each combination of gender and violation\n",
    "print(ri.groupby(['driver_gender', 'violation']).search_conducted.mean())\n",
    "\n",
    "# Reverse the ordering to group by violation before gender\n",
    "print(ri.groupby(['violation', 'driver_gender']).search_conducted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting protective frisks\n",
    "\n",
    "During a vehicle search, the police officer may pat down the driver to check if they have a weapon. This is known as a \"protective frisk.\"\n",
    "\n",
    "In this exercise, you'll first check to see how many times \"Protective Frisk\" was the only search type. Then, you'll use a string method to locate all instances in which the driver was frisked.\n",
    "\n",
    "### Instructions\n",
    "* Count the `search_type` values in the `ri` DataFrame to see how many times `\"Protective Frisk\"` was the only search type.\n",
    "* Create a new column, `frisk`, that is `True` if `search_type` contains the string `\"Protective Frisk\"` and `False` otherwise.\n",
    "* Check the data type of `frisk` to confirm that it's a Boolean Series.\n",
    "* Take the sum of `frisk` to count the total number of frisks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the 'search_type' values\n",
    "print(ri['search_type'].value_counts())\n",
    "\n",
    "# Check if 'search_type' contains the string 'Protective Frisk'\n",
    "ri['frisk'] = ri.search_type.str.contains('Protective Frisk', na=False)\n",
    "\n",
    "# Check the data type of 'frisk'\n",
    "print(ri['frisk'].dtype)\n",
    "\n",
    "# Take the sum of 'frisk'\n",
    "print(ri['frisk'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing frisk rates by gender\n",
    "\n",
    "In this exercise, you'll compare the rates at which female and male drivers are frisked during a search. Are males frisked more often than females, perhaps because police officers consider them to be higher risk?\n",
    "\n",
    "Before doing any calculations, it's important to filter the DataFrame to only include the relevant subset of data, namely stops in which a search was conducted.\n",
    "\n",
    "### Instructions\n",
    "* Create a DataFrame, `searched`, that only contains rows in which `search_conducted` is `True`.\n",
    "* Take the mean of the `frisk` column to find out what percentage of searches included a frisk.\n",
    "* Calculate the frisk rate for each gender using a `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of stops in which a search was conducted\n",
    "searched = ri[ri.search_conducted == True]\n",
    "\n",
    "# Calculate the overall frisk rate by taking the mean of 'frisk'\n",
    "print(searched['frisk'].mean())\n",
    "\n",
    "# Calculate the frisk rate for each gender\n",
    "print(searched.groupby('driver_gender').frisk.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 3 - Visual exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the hourly arrest rate\n",
    "\n",
    "When a police officer stops a driver, a small percentage of those stops ends in an arrest. This is known as the arrest rate. In this exercise, you'll find out whether the arrest rate varies by time of day.\n",
    "\n",
    "First, you'll calculate the arrest rate across all stops in the `ri` DataFrame. Then, you'll calculate the hourly arrest rate by using the hour attribute of the index. The hour ranges from 0 to 23, in which:\n",
    "\n",
    "* 0 = midnight\n",
    "* 12 = noon\n",
    "* 23 = 11 PM\n",
    "\n",
    "### Instructions\n",
    "* Take the mean of the `is_arrested` column to calculate the overall arrest rate.\n",
    "* Group by the `hour` attribute of the DataFrame index to calculate the hourly arrest rate.\n",
    "* Save the hourly arrest rate Series as a new object, `hourly_arrest_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall arrest rate\n",
    "print(ri['is_arrested'].mean())\n",
    "\n",
    "# Calculate the hourly arrest rate\n",
    "print(ri.groupby(ri.index.hour).is_arrested.mean())\n",
    "\n",
    "# Save the hourly arrest rate\n",
    "hourly_arrest_rate = ri.groupby(ri.index.hour).is_arrested.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the hourly arrest rate\n",
    "\n",
    "In this exercise, you'll create a line plot from the `hourly_arrest_rate` object. A line plot is appropriate in this case because you're showing how a quantity changes over time.\n",
    "\n",
    "This plot should help you to spot some trends that may not have been obvious when examining the raw numbers!\n",
    "\n",
    "### Instructions\n",
    "* Import `matplotlib.pyplot` using the alias `plt`.\n",
    "* Create a line plot of `hourly_arrest_rate` using the `.plot()` method.\n",
    "* Label the x-axis as `'Hour'`, label the y-axis as `'Arrest Rate'`, and title the plot `'Arrest Rate by Time of Day'`.\n",
    "* Display the plot using the `.show()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a line plot of 'hourly_arrest_rate'\n",
    "plt.plot(hourly_arrest_rate)\n",
    "\n",
    "# Add the xlabel, ylabel, and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Arrest Rate')\n",
    "plt.title('Arrest Rate by Time of Day')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting drug-related stops\n",
    "\n",
    "In a small portion of traffic stops, drugs are found in the vehicle during a search. In this exercise, you'll assess whether these drug-related stops are becoming more common over time.\n",
    "\n",
    "The Boolean column `drugs_related_stop` indicates whether drugs were found during a given stop. You'll calculate the annual drug rate by resampling this column, and then you'll use a line plot to visualize how the rate has changed over time.\n",
    "\n",
    "### Instructions\n",
    "* Calculate the annual rate of drug-related stops by resampling the `drugs_related_stop` column (on the `'A'` frequency) and taking the mean.\n",
    "* Save the annual drug rate Series as a new object, `annual_drug_rate`.\n",
    "* Create a line plot of `annual_drug_rate` using the `.plot()` method.\n",
    "* Display the plot using the `.show()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annual rate of drug-related stops\n",
    "print(ri.drugs_related_stop.resample('A').mean())\n",
    "\n",
    "# Save the annual rate of drug-related stops\n",
    "annual_drug_rate = ri.drugs_related_stop.resample('A').mean()\n",
    "\n",
    "# Create a line plot of 'annual_drug_rate'\n",
    "plt.plot(annual_drug_rate)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing drug and search rates\n",
    "\n",
    "As you saw in the last exercise, the rate of drug-related stops increased significantly between 2005 and 2015. You might hypothesize that the rate of vehicle searches was also increasing, which would have led to an increase in drug-related stops even if more drivers were not carrying drugs.\n",
    "\n",
    "You can test this hypothesis by calculating the annual search rate, and then plotting it against the annual drug rate. If the hypothesis is true, then you'll see both rates increasing over time.\n",
    "\n",
    "### Instructions\n",
    "* Calculate the annual search rate by resampling the `search_conducted` column, and save the result as `annual_search_rate`.\n",
    "* Concatenate `annual_drug_rate` and `annual_search_rate` along the columns axis, and save the result as `annual`.\n",
    "* Create subplots of the drug and search rates from the `annual` DataFrame.\n",
    "* Display the subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and save the annual search rate\n",
    "annual_search_rate = ri.search_conducted.resample('A').mean()\n",
    "\n",
    "# Concatenate 'annual_drug_rate' and 'annual_search_rate'\n",
    "annual = pd.concat([annual_drug_rate, annual_search_rate], axis=1)\n",
    "\n",
    "# Create subplots from 'annual'\n",
    "annual.plot(subplots=True)\n",
    "\n",
    "# Display the subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tallying violations by district\n",
    "\n",
    "The state of Rhode Island is broken into six police districts, also known as zones. How do the zones compare in terms of what violations are caught by police?\n",
    "\n",
    "In this exercise, you'll create a frequency table to determine how many violations of each type took place in each of the six zones. Then, you'll filter the table to focus on the \"K\" zones, which you'll examine further in the next exercise.\n",
    "\n",
    "### Instructions\n",
    "* Create a frequency table from the `ri` DataFrame's `district` and `violation` columns using the `pd.crosstab()` function.\n",
    "* Save the frequency table as a new object, `all_zones`.\n",
    "* Select rows `'Zone K1'` through `'Zone K3'` from `all_zones` using the `.loc[]` accessor.\n",
    "* Save the smaller table as a new object, `k_zones`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency table of districts and violations\n",
    "print(pd.crosstab(ri['district'], ri['violation']))\n",
    "\n",
    "# Save the frequency table as 'all_zones'\n",
    "all_zones = pd.crosstab(ri['district'], ri['violation'])\n",
    "\n",
    "# Select rows 'Zone K1' through 'Zone K3'\n",
    "print(all_zones.loc['Zone K1':'Zone K3', ])\n",
    "\n",
    "# Save the smaller table as 'k_zones'\n",
    "k_zones = all_zones.loc['Zone K1':'Zone K3', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting violations by district\n",
    "\n",
    "Now that you've created a frequency table focused on the \"K\" zones, you'll visualize the data to help you compare what violations are being caught in each zone.\n",
    "\n",
    "First you'll create a bar plot, which is an appropriate plot type since you're comparing categorical data. Then you'll create a stacked bar plot in order to get a slightly different look at the data. Which plot do you find to be more insightful?\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Section 1\n",
    "* Create a bar plot of `k_zones`.\n",
    "* Display the plot and examine it. What do you notice about each of the zones?\n",
    "\n",
    "#### Section 2\n",
    "* Create a stacked bar plot of `k_zones`.\n",
    "* Display the plot and examine it. Do you notice anything different about the data than you did previously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of 'k_zones'\n",
    "k_zones.plot(kind='bar')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a stacked bar plot of 'k_zones'\n",
    "k_zones.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting stop durations to numbers\n",
    "\n",
    "In the traffic stops dataset, the stop_duration column tells you approximately how long the driver was detained by the officer. Unfortunately, the durations are stored as strings, such as '0-15 Min'. How can you make this data easier to analyze?\n",
    "\n",
    "In this exercise, you'll convert the stop durations to integers. Because the precise durations are not available, you'll have to estimate the numbers using reasonable values:\n",
    "\n",
    "* Convert `'0-15 Min'` to 8\n",
    "* Convert `'16-30 Min'` to 23\n",
    "* Convert `'30+ Min'` to 45\n",
    "\n",
    "### Instructions\n",
    "* Print the unique values in the `stop_duration` column. (This has been done for you.)\n",
    "* Create a dictionary called `mapping` that maps the `stop_duration` strings to the integers specified above.\n",
    "* Convert the `stop_duration` strings to integers using the mapping, and store the results in a new column called `stop_minutes`.\n",
    "* Print the unique values in the `stop_minutes` column, to verify that the durations were properly converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values in 'stop_duration'\n",
    "print(ri.stop_duration.unique())\n",
    "\n",
    "# Create a dictionary that maps strings to integers\n",
    "mapping = {'0-15 Min': 8,\n",
    "           '16-30 Min': 23,\n",
    "           '30+ Min': 45}\n",
    "\n",
    "# Convert the 'stop_duration' strings to integers using the 'mapping'\n",
    "ri['stop_minutes'] = ri.stop_duration.map(mapping)\n",
    "\n",
    "# Print the unique values in 'stop_minutes'\n",
    "print(ri['stop_minutes'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting stop length\n",
    "\n",
    "If you were stopped for a particular violation, how long might you expect to be detained?\n",
    "\n",
    "In this exercise, you'll visualize the average length of time drivers are stopped for each type of violation. Rather than using the violation column in this exercise, you'll use violation_raw since it contains more detailed descriptions of the violations.\n",
    "\n",
    "### Instructions\n",
    "* For each value in the `ri` DataFrame's `violation_raw` column, calculate the mean number of `stop_minutes` that a driver is detained.\n",
    "* Save the resulting Series as a new object, `stop_length`.\n",
    "* Sort `stop_length` by its values, and then visualize it using a horizontal bar plot.\n",
    "* Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean 'stop_minutes' for each value in 'violation_raw'\n",
    "print(ri.groupby('violation_raw')['stop_minutes'].mean())\n",
    "\n",
    "# Save the resulting Series as 'stop_length'\n",
    "stop_length = ri.groupby('violation_raw')['stop_minutes'].mean()\n",
    "\n",
    "# Sort 'stop_length' by its values and create a horizontal bar plot\n",
    "stop_length.sort_values().plot(kind='barh')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 4 - Analyzing the effect of weather on policing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the temperature\n",
    "\n",
    "In this exercise, you'll examine the temperature columns from the weather dataset to assess whether the data seems trustworthy. First you'll print the summary statistics, and then you'll visualize the data using a box plot.\n",
    "\n",
    "When deciding whether the values seem reasonable, keep in mind that the temperature is measured in degrees Fahrenheit, not Celsius!\n",
    "\n",
    "### Instructions\n",
    "* Read `weather.csv` into a DataFrame named `weather`.\n",
    "* Select the temperature columns (`TMIN`, `TAVG`, `TMAX`) and print their summary statistics using the `.describe()` method.\n",
    "* Create a box plot to visualize the temperature columns.\n",
    "* Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 'weather.csv' into a DataFrame named 'weather'\n",
    "weather = pd.read_csv('weather.csv')\n",
    "\n",
    "# Describe the temperature columns\n",
    "print(weather[['TMIN', 'TAVG', 'TMAX']].describe())\n",
    "\n",
    "# Create a box plot of the temperature columns\n",
    "weather[['TMIN', 'TAVG', 'TMAX']].plot(kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the temperature difference\n",
    "\n",
    "In this exercise, you'll continue to assess whether the dataset seems trustworthy by plotting the difference between the maximum and minimum temperatures.\n",
    "\n",
    "What do you notice about the resulting histogram? Does it match your expectations, or do you see anything unusual?\n",
    "\n",
    "### Instructions\n",
    "* Create a new column in the weather DataFrame named `TDIFF` that represents the difference between the maximum and minimum temperatures.\n",
    "* Print the summary statistics for `TDIFF` using the `.describe()` method.\n",
    "* Create a histogram with 20 bins to visualize TDIFF.\n",
    "* Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'TDIFF' column that represents temperature difference\n",
    "weather['TDIFF'] = weather['TMAX'] - weather['TMIN']\n",
    "\n",
    "# Describe the 'TDIFF' column\n",
    "print(weather['TDIFF'].describe())\n",
    "\n",
    "# Create a histogram with 20 bins to visualize 'TDIFF'\n",
    "weather['TDIFF'].plot(kind='hist', bins=20)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting bad weather conditions\n",
    "\n",
    "The weather DataFrame contains 20 columns that start with `'WT'`, each of which represents a bad weather condition. For example:\n",
    "\n",
    "* `WT05` indicates `\"Hail\"`\n",
    "* `WT11` indicates `\"High or damaging winds\"`\n",
    "* `WT17` indicates `\"Freezing rain\"`\n",
    "\n",
    "For every row in the dataset, each WT column contains either a 1 (meaning the condition was present that day) or `NaN` (meaning the condition was not present).\n",
    "\n",
    "In this exercise, you'll quantify `\"how bad\"` the weather was each day by counting the number of 1 values in each row.\n",
    "\n",
    "### Instructions\n",
    "* Copy the columns `WT01` through `WT22` from `weather` to a new DataFrame named `WT`.\n",
    "* Calculate the sum of each row in `WT`, and store the results in a new weather column named `bad_conditions`.\n",
    "* Replace any missing values in `bad_conditions` with a `0`. (This has been done for you.)\n",
    "* Create a histogram to visualize `bad_conditions`, and then display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy 'WT01' through 'WT22' to a new DataFrame\n",
    "WT = weather.loc[:, 'WT01':'WT22']\n",
    "\n",
    "# Calculate the sum of each row in 'WT'\n",
    "weather['bad_conditions'] = WT.sum(axis='columns')\n",
    "\n",
    "# Replace missing values in 'bad_conditions' with '0'\n",
    "weather['bad_conditions'] = weather.bad_conditions.fillna(0).astype('int')\n",
    "\n",
    "# Create a histogram to visualize 'bad_conditions'\n",
    "weather['bad_conditions'].plot(kind='hist')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating the weather conditions\n",
    "\n",
    "In the previous exercise, you counted the number of bad weather conditions each day. In this exercise, you'll use the counts to create a rating system for the weather.\n",
    "\n",
    "The counts range from 0 to 9, and should be converted to ratings as follows:\n",
    "\n",
    "* Convert 0 to `'good'`\n",
    "* Convert 1 through 4 to `'bad'`\n",
    "* Convert 5 through 9 to `'worse'`\n",
    "\n",
    "### Instructions\n",
    "* Count the unique values in the `bad_conditions` column and sort the index. (This has been done for you.)\n",
    "* Create a dictionary called `mapping` that maps the `bad_conditions` integers to strings as specified above.\n",
    "* Convert the `bad_conditions` integers to strings using the mapping and store the results in a new column called `rating`.\n",
    "* Count the unique values in `rating` to verify that the integers were properly converted to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the unique values in 'bad_conditions' and sort the index\n",
    "print(weather.bad_conditions.value_counts().sort_index())\n",
    "\n",
    "# Create a dictionary that maps integers to strings\n",
    "mapping = {0:'good',\n",
    "           1:'bad', 2:'bad', 3:'bad', 4:'bad',\n",
    "           5:'worse', 6:'worse', 7:'worse', 8:'worse', 9:'worse'}\n",
    "\n",
    "# Convert the 'bad_conditions' integers to strings using the 'mapping'\n",
    "weather['rating'] = weather.bad_conditions.map(mapping)\n",
    "\n",
    "# Count the unique values in 'rating'\n",
    "print(weather['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the data type to category\n",
    "\n",
    "Since the rating column only has a few possible values, you'll change its data type to `category` in order to store the data more efficiently. You'll also specify a logical order for the categories, which will be useful for future exercises.\n",
    "\n",
    "### Instructions\n",
    "* Create a list object called `cats` that lists the weather ratings in a logical order: `'good'`, `'bad'`, `'worse'`.\n",
    "* Change the data type of the `rating` column from `object` to `category`. Make sure to use the `cats` list to define the category ordering.\n",
    "* Examine the head of the `rating` column to confirm that the categories are logically ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of weather ratings in logical order\n",
    "cats = ['good', 'bad', 'worse']\n",
    "\n",
    "# Change the data type of 'rating' to category\n",
    "weather['rating'] = weather.rating.astype('category', ordered=True, categories=cats)\n",
    "\n",
    "# Examine the head of 'rating'\n",
    "print(weather['rating'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the DataFrames\n",
    "\n",
    "In this exercise, you'll prepare the traffic stop and weather rating DataFrames so that they're ready to be merged:\n",
    "\n",
    "* With the `ri` DataFrame, you'll move the `stop_datetime` index to a column since the index will be lost during the merge.\n",
    "* With the `weather` DataFrame, you'll select the `DATE` and `rating` columns and put them in a new DataFrame.\n",
    "\n",
    "### Instructions\n",
    "* Reset the index of the `ri` DataFrame.\n",
    "* Examine the head of `ri` to verify that `stop_datetime` is now a DataFrame column, and the index is now the default integer index.\n",
    "* Create a new DataFrame named `weather_rating` that contains only the `DATE` and `rating` columns from the `weather` DataFrame.\n",
    "* Examine the head of `weather_rating` to verify that it contains the proper columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of 'ri'\n",
    "ri.reset_index(inplace=True)\n",
    "\n",
    "# Examine the head of 'ri'\n",
    "print(ri.head())\n",
    "\n",
    "# Create a DataFrame from the 'DATE' and 'rating' columns\n",
    "weather_rating = weather[['DATE', 'rating']]\n",
    "\n",
    "# Examine the head of 'weather_rating'\n",
    "print(weather_rating.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the DataFrames\n",
    "\n",
    "In this exercise, you'll merge the `ri` and `weather_rating` DataFrames into a new DataFrame, `ri_weather`.\n",
    "\n",
    "The DataFrames will be joined using the `stop_date` column from `ri` and the `DATE` column from `weather_rating`. Thankfully the date formatting matches exactly, which is not always the case!\n",
    "\n",
    "Once the merge is complete, you'll set `stop_datetime` as the index, which is the column you saved in the previous exercise.\n",
    "\n",
    "### Instructions\n",
    "* Examine the shape of the `ri` DataFrame.\n",
    "* Merge the `ri` and `weather_rating` DataFrames using a left join.\n",
    "* Examine the shape of `ri_weather` to confirm that it has two more columns but the same number of rows as ri.\n",
    "* Replace the index of `ri_weather` with the `stop_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of 'ri'\n",
    "print(ri.shape)\n",
    "\n",
    "# Merge 'ri' and 'weather_rating' using a left join\n",
    "ri_weather = pd.merge(left=ri, right=weather_rating, left_on='stop_date', right_on='DATE', how='left')\n",
    "\n",
    "# Examine the shape of 'ri_weather'\n",
    "print(ri_weather.shape)\n",
    "\n",
    "# Set 'stop_datetime' as the index of 'ri_weather'\n",
    "ri_weather.set_index('stop_datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing arrest rates by weather rating\n",
    "\n",
    "Do police officers arrest drivers more often when the weather is bad? Find out below!\n",
    "\n",
    "* First, you'll calculate the overall arrest rate.\n",
    "* Then, you'll calculate the arrest rate for each of the weather ratings you previously assigned.\n",
    "* Finally, you'll add violation type as a second factor in the analysis, to see if that accounts for any differences in the arrest rate.\n",
    "\n",
    "Since you previously defined a logical order for the weather categories, good < bad < worse, they will be sorted that way in the results.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Section 1\n",
    "* Calculate the overall arrest rate by taking the mean of the `is_arrested` Series.\n",
    "\n",
    "#### Section 2\n",
    "* Calculate the arrest rate for each weather rating using a `.groupby()`.\n",
    "\n",
    "#### Section 3\n",
    "* Calculate the arrest rate for each combination of `violation` and `rating`. How do the arrest rates differ by group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall arrest rate\n",
    "print(ri_weather['is_arrested'].mean())\n",
    "\n",
    "# Calculate the arrest rate for each 'rating'\n",
    "print(ri_weather.groupby('rating')['is_arrested'].mean())\n",
    "\n",
    "# Calculate the arrest rate for each 'violation' and 'rating'\n",
    "print(ri_weather.groupby(['violation', 'rating'])['is_arrested'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting from a multi-indexed Series\n",
    "\n",
    "The output of a single `.groupby()` operation on multiple columns is a Series with a MultiIndex. Working with this type of object is similar to working with a DataFrame:\n",
    "\n",
    "* The outer index level is like the DataFrame rows.\n",
    "* The inner index level is like the DataFrame columns.\n",
    "\n",
    "In this exercise, you'll practice accessing data from a multi-indexed Series using the `.loc[]` accessor.\n",
    "\n",
    "### Instructions\n",
    "* Save the output of the `.groupby()` operation from the last exercise as a new object, `arrest_rate`. (This has been done for you.)\n",
    "* Print the `arrest_rate` Series and examine it.\n",
    "* Print the arrest rate for moving violations in bad weather.\n",
    "* Print the arrest rates for speeding violations in all three weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output of the groupby operation from the last exercise\n",
    "arrest_rate = ri_weather.groupby(['violation', 'rating']).is_arrested.mean()\n",
    "\n",
    "# Print the 'arrest_rate' Series\n",
    "print(arrest_rate)\n",
    "\n",
    "# Print the arrest rate for moving violations in bad weather\n",
    "print(arrest_rate.loc['Moving violation', 'bad'])\n",
    "\n",
    "# Print the arrest rates for speeding violations in all three weather conditions\n",
    "print(arrest_rate.loc['Speeding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the arrest rate data\n",
    "\n",
    "In this exercise, you'll start by reshaping the `arrest_rate` Series into a DataFrame. This is a useful step when working with any multi-indexed Series, since it enables you to access the full range of DataFrame methods.\n",
    "\n",
    "Then, you'll create the exact same DataFrame using a pivot table. This is a great example of how pandas often gives you more than one way to reach the same result!\n",
    "\n",
    "### Instructions\n",
    "* Unstack the `arrest_rate` Series to reshape it into a DataFrame.\n",
    "* Create the exact same DataFrame using a pivot table! Each of the three `.pivot_table()` parameters should be specified as one of the `ri_weather` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack the 'arrest_rate' Series into a DataFrame\n",
    "print(arrest_rate.unstack())\n",
    "\n",
    "# Create the same DataFrame using a pivot table\n",
    "print(ri_weather.pivot_table(index='violation', columns='rating', values='is_arrested'))"
   ]
  }
 ]
}